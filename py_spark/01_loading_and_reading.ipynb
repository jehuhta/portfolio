{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3b9cc3",
   "metadata": {},
   "source": [
    "# 01: Starting with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633346dd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41031007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82624515",
   "metadata": {},
   "source": [
    "### Loading Dataframe and Creating Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb10c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|  Alice|\n",
      "|  2|    Bob|\n",
      "|  3|Charlie|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Charlie\")]\n",
    "columns = [\"id\", \"name\"]\n",
    "\n",
    "# Creating the spark session\n",
    "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()\n",
    "\n",
    "# Creating a spark dataframe\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Showing the dataframe\n",
    "df.show()\n",
    "\n",
    "# It works!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f5bbdd",
   "metadata": {},
   "source": [
    "---\n",
    "### Loading and Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e63c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|  _c0|      _c1|    _c2|        _c3|           _c4|  _c5|          _c6|             _c7|    _c8|     _c9|     _c10| _c11|\n",
      "+-----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|index|  airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
      "|    0| SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|\n",
      "|    1| SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|\n",
      "|    2|  AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|\n",
      "|    3|  Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|\n",
      "|    4|  Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
      "|    5|  Vistara| UK-945|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5955|\n",
      "|    6|  Vistara| UK-927|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 6060|\n",
      "|    7|  Vistara| UK-951|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.17|        1| 6060|\n",
      "|    8| GO_FIRST| G8-334|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5954|\n",
      "|    9| GO_FIRST| G8-336|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
      "|   10| GO_FIRST| G8-392|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
      "|   11| GO_FIRST| G8-338|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5954|\n",
      "|   12|   Indigo|6E-5001|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
      "|   13|   Indigo|6E-6202|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.17|        1| 5955|\n",
      "|   14|   Indigo| 6E-549|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5955|\n",
      "|   15|   Indigo|6E-6278|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
      "|   16|Air_India| AI-887|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 5955|\n",
      "|   17|Air_India| AI-665|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
      "|   18|  AirAsia| I5-747|      Delhi|       Evening|  one|Early_Morning|          Mumbai|Economy|   12.25|        1| 5949|\n",
      "+-----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Loading from csv\n",
    "df = spark.read.csv('./datasets/airlines_flights_data.csv')\n",
    "\n",
    "# Notice how the header isn't functioning correctly.\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9970a733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|index|  airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
      "+-----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|    0| SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|\n",
      "|    1| SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|\n",
      "|    2|  AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|\n",
      "|    3|  Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|\n",
      "|    4|  Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
      "|    5|  Vistara| UK-945|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5955|\n",
      "|    6|  Vistara| UK-927|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 6060|\n",
      "|    7|  Vistara| UK-951|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.17|        1| 6060|\n",
      "|    8| GO_FIRST| G8-334|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5954|\n",
      "|    9| GO_FIRST| G8-336|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
      "|   10| GO_FIRST| G8-392|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
      "|   11| GO_FIRST| G8-338|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5954|\n",
      "|   12|   Indigo|6E-5001|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
      "|   13|   Indigo|6E-6202|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.17|        1| 5955|\n",
      "|   14|   Indigo| 6E-549|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5955|\n",
      "|   15|   Indigo|6E-6278|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
      "|   16|Air_India| AI-887|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 5955|\n",
      "|   17|Air_India| AI-665|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
      "|   18|  AirAsia| I5-747|      Delhi|       Evening|  one|Early_Morning|          Mumbai|Economy|   12.25|        1| 5949|\n",
      "|   19|  AirAsia| I5-747|      Delhi|       Evening|  one|      Morning|          Mumbai|Economy|   16.33|        1| 5949|\n",
      "+-----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Fixing headers as the first row\n",
    "df = spark.read.option('header','true').csv('./datasets/airlines_flights_data.csv')\n",
    "\n",
    "# Now it functions correctly\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a5aca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- source_city: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- stops: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- days_left: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing Schema.\n",
    "df.printSchema()\n",
    "\n",
    "# Notice how some variables are ``string``, even though they should be ``int`` datatype. Let's fix that in the next code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e22ed1",
   "metadata": {},
   "source": [
    "### Inferring Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c7653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- source_city: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- stops: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- days_left: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fixing the schema's datatypes is done via loading with inferschema.\n",
    "df = spark.read.option('header','true').csv('./datasets/airlines_flights_data.csv', inferSchema=True)\n",
    "\n",
    "# Notice how it fixes these \n",
    "df.printSchema()\n",
    "\n",
    "# But this can be inefficient, because it meticulously reads the whole file line by line, taking computing power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3576b9e",
   "metadata": {},
   "source": [
    "### Using a pre-determined schema up the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb6dd6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Airline: string (nullable = true)\n",
      " |-- FlightNum: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- DepDelay: double (nullable = true)\n",
      " |-- ArrDelay: double (nullable = true)\n",
      " |-- Distance: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This needs a new import. The datatypes you'll use are places after 'import'.\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "\n",
    "# Example schema definition (you need to adjust this to your actual CSV columns)\n",
    "schema = StructType([\n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Month\", IntegerType(), True),\n",
    "    StructField(\"DayofMonth\", IntegerType(), True),\n",
    "    StructField(\"DayOfWeek\", IntegerType(), True),\n",
    "    StructField(\"Airline\", StringType(), True),\n",
    "    StructField(\"FlightNum\", StringType(), True),\n",
    "    StructField(\"Origin\", StringType(), True),\n",
    "    StructField(\"Dest\", StringType(), True),\n",
    "    StructField(\"DepTime\", StringType(), True),  \n",
    "    StructField(\"ArrTime\", StringType(), True),   \n",
    "    StructField(\"DepDelay\", DoubleType(), True),\n",
    "    StructField(\"ArrDelay\", DoubleType(), True),\n",
    "    StructField(\"Distance\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Load with predefined schema\n",
    "df = spark.read.option(\"header\", \"true\").schema(schema).csv(\"./datasets/airlines_flights_data.csv\")\n",
    "\n",
    "# Printing Schema\n",
    "df.printSchema()\n",
    "\n",
    "# This is faster and more efficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
